{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "We will go through a complete 4-step workflow of the tool use\n",
    "\n",
    "1. Send the user query to the LLM and LLM decides whether to use tool\n",
    "2. If using tool, LLM will send back a tool use message including the too name and the tool input\n",
    "3. On user side, the corresponding tool will be called and the tool will return the result\n",
    "4. The LLM will then see the tool output and continue the conversation\n",
    "\n",
    "\n",
    "Tool use is a really general enhancement for LLM. For example, RAG can be seen as a tool. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_search_tool = {\n",
    "    \"name\": \"get_article\",\n",
    "    \"description\": \"A tool to retrieve an up to date Wikipedia article.\",\n",
    "    \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"search_term\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The search term to find a wikipedia article by title\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"search_term\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(search_term):\n",
    "    results = wikipedia.search(search_term)\n",
    "    first_result = results[0]\n",
    "    page = wikipedia.page(first_result, auto_suggest=False)\n",
    "    return page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"claude-3-7-sonnet-20250219\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_answers(text):\n",
    "    \"\"\"\n",
    "    Extracts all text between <answer> and </answer> tags.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input string containing <answer> tags.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: A list of extracted text between the tags.\n",
    "    \"\"\"\n",
    "    pattern = r\"<answer>(.*?)</answer>\"\n",
    "    ans = re.findall(pattern, text, re.DOTALL)\n",
    "    return \" \".join(ans) if ans else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question):\n",
    "    system_prompt = \"\"\"\n",
    "    You will be asked a question by the user. \n",
    "    If answering the question requires data you were not trained on, you can use the get_article tool to get the contents of a recent wikipedia article about the topic. \n",
    "    If you can answer the question without needing to get more information, please do so. \n",
    "    Only call the tool when needed. \n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Answer the following question <question>{question}</question>\n",
    "    When you can answer the question, keep your answer as short as possible and enclose it in <answer> tags\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    response = client.messages.create(\n",
    "        model=model,\n",
    "        system=system_prompt, \n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "        tools=[article_search_tool]\n",
    "    )\n",
    "    \n",
    "    print(f\"Claude's response: {response}\")\n",
    "    \n",
    "    # Claude might generate multiple tool use messages. Use a while loop to handle all of them\n",
    "    while(response.stop_reason == \"tool_use\"):\n",
    "        tool_use = response.content[-1]\n",
    "        tool_name = tool_use.name\n",
    "        tool_input = tool_use.input\n",
    "        #Add Claude's tool use call to messages:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
    "\n",
    "        if tool_name == \"get_article\":\n",
    "            search_term = tool_input[\"search_term\"]\n",
    "            print(f\"Claude wants to get an article for {search_term}\")\n",
    "            wiki_result = get_article(search_term) #get wikipedia article content\n",
    "            #construct our tool_result message\n",
    "            tool_response = {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                    \"type\": \"tool_result\",\n",
    "                    \"tool_use_id\": tool_use.id,\n",
    "                    \"content\": wiki_result\n",
    "                    }\n",
    "                ]\n",
    "                }\n",
    "            messages.append(tool_response)\n",
    "            #respond back to Claude\n",
    "            response = client.messages.create(\n",
    "                model=model,\n",
    "                system=system_prompt, \n",
    "                messages=messages,\n",
    "                max_tokens=1000,\n",
    "                tools=[article_search_tool]\n",
    "            )\n",
    "    print(\"Claude's final answer:\")\n",
    "    print(extract_answers(response.content[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude's response: Message(id='msg_01TBZf9ZfLSA8HjH3Swt6eNj', content=[TextBlock(citations=None, text=\"I'll need to check on Christopher Nolan's Oscar wins and Ben Stiller's Emmy wins to answer this question accurately. Let me look up the information.\", type='text'), ToolUseBlock(id='toolu_01HD9cUPe2iYU5dqnGZaJPQp', input={'search_term': 'Christopher Nolan'}, name='get_article', type='tool_use')], model='claude-3-7-sonnet-20250219', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=546, output_tokens=93, server_tool_use=None, service_tier='standard'))\n",
      "Claude wants to get an article for Christopher Nolan\n",
      "Claude wants to get an article for Ben Stiller\n",
      "Claude's final answer:\n",
      "Christopher Nolan has two Academy Awards (Oscars), which he won for Best Director and Best Picture for \"Oppenheimer\" (2023). Ben Stiller has one Emmy Award, which he won for \"Outstanding Writing for a Variety Program\" for \"The Ben Stiller Show\" in the early 1990s. So Christopher Nolan has more Oscars than Ben Stiller has Emmys.\n"
     ]
    }
   ],
   "source": [
    "question = \"How many Oscars does Christopher Nolan have?  Does he have more than the number of Emmy's that Ben Stiller has?\"\n",
    "answer_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
